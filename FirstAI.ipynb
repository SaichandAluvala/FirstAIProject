{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {},
   "source": [
    "\n",
    "from secret_key import openapi_key\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = openapi_key\n",
    "\n",
    "print(os.getenv('OPENAI_API_KEY'))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#import neccasary modules for project requirements \n",
    "!pip install langchain-community\n",
    "!pip install transformers\n",
    "!pip install huggingface_hub\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!pip install --upgrade langchain-community\n",
    "\n",
    "!pip install langchain-chains\n",
    "\n"
   ],
   "id": "7cc9663cf14a232d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Install necessary packages if not already installed\n",
    "# !pip install langchain-community\n",
    "# !pip install transformers\n",
    "\n",
    "# Import the HuggingFaceEndpoint from langchain_community.llms\n",
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "\n",
    "\n",
    "\n",
    "# Set your Hugging Face API token\n",
    "HUGGINGFACEHUB_API_TOKEN = \"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\"\n",
    "\n",
    "# Explicitly set the environment variable for the Hugging Face API token\n",
    "import os\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = HUGGINGFACEHUB_API_TOKEN\n",
    "\n",
    "# Authenticate with Hugging Face using the token\n",
    "from huggingface_hub import login\n",
    "login(HUGGINGFACEHUB_API_TOKEN)\n",
    "\n",
    "# Instantiate the HuggingFaceEndpoint\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    temperature=0.7,\n",
    "    model_kwargs={ \n",
    "        \"max_length\": 50 \n",
    "    }\n",
    ")\n",
    "# Generate restaurant name \n",
    "restaurant_prompt = \"I want to start a indian food restaurant. give me the top 10 best dishes in india\"\n",
    "restaurant_name = llm(restaurant_prompt)\n",
    "print(restaurant_name)\n"
   ],
   "id": "856de66e656673f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T07:29:46.477713Z",
     "start_time": "2024-06-25T07:29:46.471433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "#import PromptTemplate from langchain.prompts\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template=\"I want to start a {cuisine} food restaurant. give me the top 10 best dishes in {cuisine}\"  \n",
    ")\n",
    "prompt_template_name.format(cuisine=\"Russia\")\n"
   ],
   "id": "f5219127e2f20f01",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to start a Russia food restaurant. give me the top 10 best dishes in Russia'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Generate Food Items of Restaurant which given by user\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "# Instantiate the HuggingFaceEndpoint\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    temperature=0.7,  \n",
    "    model_kwargs={\n",
    "        \"max_length\": 50\n",
    "    }\n",
    ")\n",
    "\n",
    "# Define the prompt template for restaurant name\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template=\"I want to start a {cuisine} food restaurant. Give me 1 best restaurant name only.\"\n",
    ")\n",
    "#resturant_name=llm(prompt_template_name.template)\n",
    "#print(restaurant_name) restaurant name will be given by LLM\n",
    " \n",
    "# Define the LLMChain for restaurant name\n",
    "name_chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
    "\n",
    "# Define the prompt template for food items\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables=['restaurant_name'],\n",
    "    template=\"Give me the top 10 best food items from {restaurant_name} food restaurant separated by commas.\"\n",
    ")\n",
    "\n",
    "# Define the LLMChain for food items\n",
    "food_items_chain = LLMChain(llm=llm, prompt=prompt_template_items)\n",
    "\n",
    "# Instantiate SimpleSequentialChain with LLMChain instances\n",
    "chain = SimpleSequentialChain(chains=[name_chain, food_items_chain])\n",
    " \n",
    "# Run the chain with a specific input    \n",
    "response = chain.run(\"Indian\") \n",
    "print(response) \n"
   ],
   "id": "7cd4f2e936811d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Generate Restaurant name and Food Items of Restaurant which given by user\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "\n",
    "# Instantiate the HuggingFaceEndpoint\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    temperature=0.6,\n",
    "    model_kwargs={\n",
    "        \"max_length\": 50\n",
    "    }\n",
    ")\n",
    "\n",
    "# Define the prompt template for restaurant name\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template=\"I want to start a {cuisine} food restaurant. Give me 1 best restaurant name only.\"\n",
    ")\n",
    "\n",
    "# Define the LLMChain for restaurant name\n",
    "name_chain = LLMChain(llm=llm, prompt=prompt_template_name, output_key=\"restaurant_name\")\n",
    "\n",
    "# Define the prompt template for food items\n",
    "prompt_template_items = PromptTemplate( \n",
    "    input_variables=['restaurant_name'],\n",
    "    template=\"Give me the top 10 best food items from {restaurant_name} food restaurant separated by commas.\"\n",
    ")\n",
    "\n",
    "# Define the LLMChain for food items\n",
    "food_items_chain = LLMChain(llm=llm, prompt=prompt_template_items, output_key=\"food_items\")\n",
    "\n",
    "# Instantiate SequentialChain with LLMChain instances \n",
    "chain = SequentialChain(\n",
    "    chains=[name_chain, food_items_chain],\n",
    "    input_variables=[\"cuisine\"],     \n",
    "    output_variables=['restaurant_name', 'food_items'] \n",
    ")\n",
    "\n",
    "# Run the chain   \n",
    "chain({'cuisine': 'Indian'})     \n",
    "\n",
    " "
   ],
   "id": "53e243f47df6c04e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "54b2c633127f712f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
